{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Example:\n",
    "import json\n",
    "import difflib\n",
    "\n",
    "# json file downloaded from https://raw.githubusercontent.com/matthewreagan/WebstersEnglishDictionary/master/dictionary.json\n",
    "# load the json data into python object\n",
    "json_dictionary = dict()\n",
    "with open(\"dictionary.json\") as dictionary_file:\n",
    "    json_dictionary = json.load(dictionary_file)\n",
    "\n",
    "\n",
    "def getMeaning(in_word):\n",
    "    keys = json_dictionary.keys()\n",
    "    if(in_word in keys):\n",
    "        return json_dictionary[in_word.lower()]\n",
    "    elif(len(difflib.get_close_matches(in_word, keys))>0):    \n",
    "        print(difflib.get_close_matches(in_word, keys))\n",
    "        yn = input(\"Did you mean {p_word} instead? Y/N : \".format(p_word = difflib.get_close_matches(in_word, keys, n=1)))\n",
    "        if yn.upper() == 'Y':\n",
    "            return json_dictionary[difflib.get_close_matches(in_word, keys, n=1)[0]]\n",
    "        elif yn.upper() == 'N':\n",
    "            print(\"Word : {in_word} not found\".format(in_word=in_word)) \n",
    "        else:\n",
    "            print(\"Sorry ! input not understood.\") \n",
    "    else:    \n",
    "        print(\"Word : {in_word} not found\".format(in_word=in_word)) \n",
    "\n",
    "            \n",
    "# get input from the user    \n",
    "in_word = input(\"Search meaning of word : \")\n",
    "getMeaning(in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module difflib:\n",
      "\n",
      "NAME\n",
      "    difflib - Module difflib -- helpers for computing deltas between objects.\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.8/library/difflib\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    Function get_close_matches(word, possibilities, n=3, cutoff=0.6):\n",
      "        Use SequenceMatcher to return list of the best \"good enough\" matches.\n",
      "    \n",
      "    Function context_diff(a, b):\n",
      "        For two lists of strings, return a delta in context diff format.\n",
      "    \n",
      "    Function ndiff(a, b):\n",
      "        Return a delta: the difference between `a` and `b` (lists of strings).\n",
      "    \n",
      "    Function restore(delta, which):\n",
      "        Return one of the two sequences that generated an ndiff delta.\n",
      "    \n",
      "    Function unified_diff(a, b):\n",
      "        For two lists of strings, return a delta in unified diff format.\n",
      "    \n",
      "    Class SequenceMatcher:\n",
      "        A flexible class for comparing pairs of sequences of any type.\n",
      "    \n",
      "    Class Differ:\n",
      "        For producing human-readable deltas from sequences of lines of text.\n",
      "    \n",
      "    Class HtmlDiff:\n",
      "        For producing HTML side by side comparison with change highlights.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Differ\n",
      "        HtmlDiff\n",
      "        SequenceMatcher\n",
      "    builtins.tuple(builtins.object)\n",
      "        Match\n",
      "    \n",
      "    class Differ(builtins.object)\n",
      "     |  Differ(linejunk=None, charjunk=None)\n",
      "     |  \n",
      "     |  Differ is a class for comparing sequences of lines of text, and\n",
      "     |  producing human-readable differences or deltas.  Differ uses\n",
      "     |  SequenceMatcher both to compare sequences of lines, and to compare\n",
      "     |  sequences of characters within similar (near-matching) lines.\n",
      "     |  \n",
      "     |  Each line of a Differ delta begins with a two-letter code:\n",
      "     |  \n",
      "     |      '- '    line unique to sequence 1\n",
      "     |      '+ '    line unique to sequence 2\n",
      "     |      '  '    line common to both sequences\n",
      "     |      '? '    line not present in either input sequence\n",
      "     |  \n",
      "     |  Lines beginning with '? ' attempt to guide the eye to intraline\n",
      "     |  differences, and were not present in either input sequence.  These lines\n",
      "     |  can be confusing if the sequences contain tab characters.\n",
      "     |  \n",
      "     |  Note that Differ makes no claim to produce a *minimal* diff.  To the\n",
      "     |  contrary, minimal diffs are often counter-intuitive, because they synch\n",
      "     |  up anywhere possible, sometimes accidental matches 100 pages apart.\n",
      "     |  Restricting synch points to contiguous matches preserves some notion of\n",
      "     |  locality, at the occasional cost of producing a longer diff.\n",
      "     |  \n",
      "     |  Example: Comparing two texts.\n",
      "     |  \n",
      "     |  First we set up the texts, sequences of individual single-line strings\n",
      "     |  ending with newlines (such sequences can also be obtained from the\n",
      "     |  `readlines()` method of file-like objects):\n",
      "     |  \n",
      "     |  >>> text1 = '''  1. Beautiful is better than ugly.\n",
      "     |  ...   2. Explicit is better than implicit.\n",
      "     |  ...   3. Simple is better than complex.\n",
      "     |  ...   4. Complex is better than complicated.\n",
      "     |  ... '''.splitlines(keepends=True)\n",
      "     |  >>> len(text1)\n",
      "     |  4\n",
      "     |  >>> text1[0][-1]\n",
      "     |  '\\n'\n",
      "     |  >>> text2 = '''  1. Beautiful is better than ugly.\n",
      "     |  ...   3.   Simple is better than complex.\n",
      "     |  ...   4. Complicated is better than complex.\n",
      "     |  ...   5. Flat is better than nested.\n",
      "     |  ... '''.splitlines(keepends=True)\n",
      "     |  \n",
      "     |  Next we instantiate a Differ object:\n",
      "     |  \n",
      "     |  >>> d = Differ()\n",
      "     |  \n",
      "     |  Note that when instantiating a Differ object we may pass functions to\n",
      "     |  filter out line and character 'junk'.  See Differ.__init__ for details.\n",
      "     |  \n",
      "     |  Finally, we compare the two:\n",
      "     |  \n",
      "     |  >>> result = list(d.compare(text1, text2))\n",
      "     |  \n",
      "     |  'result' is a list of strings, so let's pretty-print it:\n",
      "     |  \n",
      "     |  >>> from pprint import pprint as _pprint\n",
      "     |  >>> _pprint(result)\n",
      "     |  ['    1. Beautiful is better than ugly.\\n',\n",
      "     |   '-   2. Explicit is better than implicit.\\n',\n",
      "     |   '-   3. Simple is better than complex.\\n',\n",
      "     |   '+   3.   Simple is better than complex.\\n',\n",
      "     |   '?     ++\\n',\n",
      "     |   '-   4. Complex is better than complicated.\\n',\n",
      "     |   '?            ^                     ---- ^\\n',\n",
      "     |   '+   4. Complicated is better than complex.\\n',\n",
      "     |   '?           ++++ ^                      ^\\n',\n",
      "     |   '+   5. Flat is better than nested.\\n']\n",
      "     |  \n",
      "     |  As a single multi-line string it looks like this:\n",
      "     |  \n",
      "     |  >>> print(''.join(result), end=\"\")\n",
      "     |      1. Beautiful is better than ugly.\n",
      "     |  -   2. Explicit is better than implicit.\n",
      "     |  -   3. Simple is better than complex.\n",
      "     |  +   3.   Simple is better than complex.\n",
      "     |  ?     ++\n",
      "     |  -   4. Complex is better than complicated.\n",
      "     |  ?            ^                     ---- ^\n",
      "     |  +   4. Complicated is better than complex.\n",
      "     |  ?           ++++ ^                      ^\n",
      "     |  +   5. Flat is better than nested.\n",
      "     |  \n",
      "     |  Methods:\n",
      "     |  \n",
      "     |  __init__(linejunk=None, charjunk=None)\n",
      "     |      Construct a text differencer, with optional filters.\n",
      "     |  \n",
      "     |  compare(a, b)\n",
      "     |      Compare two sequences of lines; generate the resulting delta.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, linejunk=None, charjunk=None)\n",
      "     |      Construct a text differencer, with optional filters.\n",
      "     |      \n",
      "     |      The two optional keyword parameters are for filter functions:\n",
      "     |      \n",
      "     |      - `linejunk`: A function that should accept a single string argument,\n",
      "     |        and return true iff the string is junk. The module-level function\n",
      "     |        `IS_LINE_JUNK` may be used to filter out lines without visible\n",
      "     |        characters, except for at most one splat ('#').  It is recommended\n",
      "     |        to leave linejunk None; the underlying SequenceMatcher class has\n",
      "     |        an adaptive notion of \"noise\" lines that's better than any static\n",
      "     |        definition the author has ever been able to craft.\n",
      "     |      \n",
      "     |      - `charjunk`: A function that should accept a string of length 1. The\n",
      "     |        module-level function `IS_CHARACTER_JUNK` may be used to filter out\n",
      "     |        whitespace characters (a blank or tab; **note**: bad idea to include\n",
      "     |        newline in this!).  Use of IS_CHARACTER_JUNK is recommended.\n",
      "     |  \n",
      "     |  compare(self, a, b)\n",
      "     |      Compare two sequences of lines; generate the resulting delta.\n",
      "     |      \n",
      "     |      Each sequence must contain individual single-line strings ending with\n",
      "     |      newlines. Such sequences can be obtained from the `readlines()` method\n",
      "     |      of file-like objects.  The delta generated also consists of newline-\n",
      "     |      terminated strings, ready to be printed as-is via the writeline()\n",
      "     |      method of a file-like object.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> print(''.join(Differ().compare('one\\ntwo\\nthree\\n'.splitlines(True),\n",
      "     |      ...                                'ore\\ntree\\nemu\\n'.splitlines(True))),\n",
      "     |      ...       end=\"\")\n",
      "     |      - one\n",
      "     |      ?  ^\n",
      "     |      + ore\n",
      "     |      ?  ^\n",
      "     |      - two\n",
      "     |      - three\n",
      "     |      ?  -\n",
      "     |      + tree\n",
      "     |      + emu\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class HtmlDiff(builtins.object)\n",
      "     |  HtmlDiff(tabsize=8, wrapcolumn=None, linejunk=None, charjunk=<function IS_CHARACTER_JUNK at 0x000002595F2DCF70>)\n",
      "     |  \n",
      "     |  For producing HTML side by side comparison with change highlights.\n",
      "     |  \n",
      "     |  This class can be used to create an HTML table (or a complete HTML file\n",
      "     |  containing the table) showing a side by side, line by line comparison\n",
      "     |  of text with inter-line and intra-line change highlights.  The table can\n",
      "     |  be generated in either full or contextual difference mode.\n",
      "     |  \n",
      "     |  The following methods are provided for HTML generation:\n",
      "     |  \n",
      "     |  make_table -- generates HTML for a single side by side table\n",
      "     |  make_file -- generates complete HTML file with a single side by side table\n",
      "     |  \n",
      "     |  See tools/scripts/diff.py for an example usage of this class.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, tabsize=8, wrapcolumn=None, linejunk=None, charjunk=<function IS_CHARACTER_JUNK at 0x000002595F2DCF70>)\n",
      "     |      HtmlDiff instance initializer\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |      tabsize -- tab stop spacing, defaults to 8.\n",
      "     |      wrapcolumn -- column number where lines are broken and wrapped,\n",
      "     |          defaults to None where lines are not wrapped.\n",
      "     |      linejunk,charjunk -- keyword arguments passed into ndiff() (used by\n",
      "     |          HtmlDiff() to generate the side by side HTML differences).  See\n",
      "     |          ndiff() documentation for argument default values and descriptions.\n",
      "     |  \n",
      "     |  make_file(self, fromlines, tolines, fromdesc='', todesc='', context=False, numlines=5, *, charset='utf-8')\n",
      "     |      Returns HTML file of side by side comparison with change highlights\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |      fromlines -- list of \"from\" lines\n",
      "     |      tolines -- list of \"to\" lines\n",
      "     |      fromdesc -- \"from\" file column header string\n",
      "     |      todesc -- \"to\" file column header string\n",
      "     |      context -- set to True for contextual differences (defaults to False\n",
      "     |          which shows full differences).\n",
      "     |      numlines -- number of context lines.  When context is set True,\n",
      "     |          controls number of lines displayed before and after the change.\n",
      "     |          When context is False, controls the number of lines to place\n",
      "     |          the \"next\" link anchors before the next change (so click of\n",
      "     |          \"next\" link jumps to just before the change).\n",
      "     |      charset -- charset of the HTML document\n",
      "     |  \n",
      "     |  make_table(self, fromlines, tolines, fromdesc='', todesc='', context=False, numlines=5)\n",
      "     |      Returns HTML table of side by side comparison with change highlights\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |      fromlines -- list of \"from\" lines\n",
      "     |      tolines -- list of \"to\" lines\n",
      "     |      fromdesc -- \"from\" file column header string\n",
      "     |      todesc -- \"to\" file column header string\n",
      "     |      context -- set to True for contextual differences (defaults to False\n",
      "     |          which shows full differences).\n",
      "     |      numlines -- number of context lines.  When context is set True,\n",
      "     |          controls number of lines displayed before and after the change.\n",
      "     |          When context is False, controls the number of lines to place\n",
      "     |          the \"next\" link anchors before the next change (so click of\n",
      "     |          \"next\" link jumps to just before the change).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Match(builtins.tuple)\n",
      "     |  Match(a, b, size)\n",
      "     |  \n",
      "     |  Match(a, b, size)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Match\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new Match object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new Match object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(_cls, a, b, size)\n",
      "     |      Create new instance of Match(a, b, size)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  a\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  b\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  size\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('a', 'b', 'size')\n",
      "     |  \n",
      "     |  _fields_defaults = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class SequenceMatcher(builtins.object)\n",
      "     |  SequenceMatcher(isjunk=None, a='', b='', autojunk=True)\n",
      "     |  \n",
      "     |  SequenceMatcher is a flexible class for comparing pairs of sequences of\n",
      "     |  any type, so long as the sequence elements are hashable.  The basic\n",
      "     |  algorithm predates, and is a little fancier than, an algorithm\n",
      "     |  published in the late 1980's by Ratcliff and Obershelp under the\n",
      "     |  hyperbolic name \"gestalt pattern matching\".  The basic idea is to find\n",
      "     |  the longest contiguous matching subsequence that contains no \"junk\"\n",
      "     |  elements (R-O doesn't address junk).  The same idea is then applied\n",
      "     |  recursively to the pieces of the sequences to the left and to the right\n",
      "     |  of the matching subsequence.  This does not yield minimal edit\n",
      "     |  sequences, but does tend to yield matches that \"look right\" to people.\n",
      "     |  \n",
      "     |  SequenceMatcher tries to compute a \"human-friendly diff\" between two\n",
      "     |  sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the\n",
      "     |  longest *contiguous* & junk-free matching subsequence.  That's what\n",
      "     |  catches peoples' eyes.  The Windows(tm) windiff has another interesting\n",
      "     |  notion, pairing up elements that appear uniquely in each sequence.\n",
      "     |  That, and the method here, appear to yield more intuitive difference\n",
      "     |  reports than does diff.  This method appears to be the least vulnerable\n",
      "     |  to synching up on blocks of \"junk lines\", though (like blank lines in\n",
      "     |  ordinary text files, or maybe \"<P>\" lines in HTML files).  That may be\n",
      "     |  because this is the only method of the 3 that has a *concept* of\n",
      "     |  \"junk\" <wink>.\n",
      "     |  \n",
      "     |  Example, comparing two strings, and considering blanks to be \"junk\":\n",
      "     |  \n",
      "     |  >>> s = SequenceMatcher(lambda x: x == \" \",\n",
      "     |  ...                     \"private Thread currentThread;\",\n",
      "     |  ...                     \"private volatile Thread currentThread;\")\n",
      "     |  >>>\n",
      "     |  \n",
      "     |  .ratio() returns a float in [0, 1], measuring the \"similarity\" of the\n",
      "     |  sequences.  As a rule of thumb, a .ratio() value over 0.6 means the\n",
      "     |  sequences are close matches:\n",
      "     |  \n",
      "     |  >>> print(round(s.ratio(), 3))\n",
      "     |  0.866\n",
      "     |  >>>\n",
      "     |  \n",
      "     |  If you're only interested in where the sequences match,\n",
      "     |  .get_matching_blocks() is handy:\n",
      "     |  \n",
      "     |  >>> for block in s.get_matching_blocks():\n",
      "     |  ...     print(\"a[%d] and b[%d] match for %d elements\" % block)\n",
      "     |  a[0] and b[0] match for 8 elements\n",
      "     |  a[8] and b[17] match for 21 elements\n",
      "     |  a[29] and b[38] match for 0 elements\n",
      "     |  \n",
      "     |  Note that the last tuple returned by .get_matching_blocks() is always a\n",
      "     |  dummy, (len(a), len(b), 0), and this is the only case in which the last\n",
      "     |  tuple element (number of elements matched) is 0.\n",
      "     |  \n",
      "     |  If you want to know how to change the first sequence into the second,\n",
      "     |  use .get_opcodes():\n",
      "     |  \n",
      "     |  >>> for opcode in s.get_opcodes():\n",
      "     |  ...     print(\"%6s a[%d:%d] b[%d:%d]\" % opcode)\n",
      "     |   equal a[0:8] b[0:8]\n",
      "     |  insert a[8:8] b[8:17]\n",
      "     |   equal a[8:29] b[17:38]\n",
      "     |  \n",
      "     |  See the Differ class for a fancy human-friendly file differencer, which\n",
      "     |  uses SequenceMatcher both to compare sequences of lines, and to compare\n",
      "     |  sequences of characters within similar (near-matching) lines.\n",
      "     |  \n",
      "     |  See also function get_close_matches() in this module, which shows how\n",
      "     |  simple code building on SequenceMatcher can be used to do useful work.\n",
      "     |  \n",
      "     |  Timing:  Basic R-O is cubic time worst case and quadratic time expected\n",
      "     |  case.  SequenceMatcher is quadratic time for the worst case and has\n",
      "     |  expected-case behavior dependent in a complicated way on how many\n",
      "     |  elements the sequences have in common; best case time is linear.\n",
      "     |  \n",
      "     |  Methods:\n",
      "     |  \n",
      "     |  __init__(isjunk=None, a='', b='')\n",
      "     |      Construct a SequenceMatcher.\n",
      "     |  \n",
      "     |  set_seqs(a, b)\n",
      "     |      Set the two sequences to be compared.\n",
      "     |  \n",
      "     |  set_seq1(a)\n",
      "     |      Set the first sequence to be compared.\n",
      "     |  \n",
      "     |  set_seq2(b)\n",
      "     |      Set the second sequence to be compared.\n",
      "     |  \n",
      "     |  find_longest_match(alo, ahi, blo, bhi)\n",
      "     |      Find longest matching block in a[alo:ahi] and b[blo:bhi].\n",
      "     |  \n",
      "     |  get_matching_blocks()\n",
      "     |      Return list of triples describing matching subsequences.\n",
      "     |  \n",
      "     |  get_opcodes()\n",
      "     |      Return list of 5-tuples describing how to turn a into b.\n",
      "     |  \n",
      "     |  ratio()\n",
      "     |      Return a measure of the sequences' similarity (float in [0,1]).\n",
      "     |  \n",
      "     |  quick_ratio()\n",
      "     |      Return an upper bound on .ratio() relatively quickly.\n",
      "     |  \n",
      "     |  real_quick_ratio()\n",
      "     |      Return an upper bound on ratio() very quickly.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, isjunk=None, a='', b='', autojunk=True)\n",
      "     |      Construct a SequenceMatcher.\n",
      "     |      \n",
      "     |      Optional arg isjunk is None (the default), or a one-argument\n",
      "     |      function that takes a sequence element and returns true iff the\n",
      "     |      element is junk.  None is equivalent to passing \"lambda x: 0\", i.e.\n",
      "     |      no elements are considered to be junk.  For example, pass\n",
      "     |          lambda x: x in \" \\t\"\n",
      "     |      if you're comparing lines as sequences of characters, and don't\n",
      "     |      want to synch up on blanks or hard tabs.\n",
      "     |      \n",
      "     |      Optional arg a is the first of two sequences to be compared.  By\n",
      "     |      default, an empty string.  The elements of a must be hashable.  See\n",
      "     |      also .set_seqs() and .set_seq1().\n",
      "     |      \n",
      "     |      Optional arg b is the second of two sequences to be compared.  By\n",
      "     |      default, an empty string.  The elements of b must be hashable. See\n",
      "     |      also .set_seqs() and .set_seq2().\n",
      "     |      \n",
      "     |      Optional arg autojunk should be set to False to disable the\n",
      "     |      \"automatic junk heuristic\" that treats popular elements as junk\n",
      "     |      (see module documentation for more information).\n",
      "     |  \n",
      "     |  find_longest_match(self, alo, ahi, blo, bhi)\n",
      "     |      Find longest matching block in a[alo:ahi] and b[blo:bhi].\n",
      "     |      \n",
      "     |      If isjunk is not defined:\n",
      "     |      \n",
      "     |      Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where\n",
      "     |          alo <= i <= i+k <= ahi\n",
      "     |          blo <= j <= j+k <= bhi\n",
      "     |      and for all (i',j',k') meeting those conditions,\n",
      "     |          k >= k'\n",
      "     |          i <= i'\n",
      "     |          and if i == i', j <= j'\n",
      "     |      \n",
      "     |      In other words, of all maximal matching blocks, return one that\n",
      "     |      starts earliest in a, and of all those maximal matching blocks that\n",
      "     |      start earliest in a, return the one that starts earliest in b.\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(None, \" abcd\", \"abcd abcd\")\n",
      "     |      >>> s.find_longest_match(0, 5, 0, 9)\n",
      "     |      Match(a=0, b=4, size=5)\n",
      "     |      \n",
      "     |      If isjunk is defined, first the longest matching block is\n",
      "     |      determined as above, but with the additional restriction that no\n",
      "     |      junk element appears in the block.  Then that block is extended as\n",
      "     |      far as possible by matching (only) junk elements on both sides.  So\n",
      "     |      the resulting block never matches on junk except as identical junk\n",
      "     |      happens to be adjacent to an \"interesting\" match.\n",
      "     |      \n",
      "     |      Here's the same example as before, but considering blanks to be\n",
      "     |      junk.  That prevents \" abcd\" from matching the \" abcd\" at the tail\n",
      "     |      end of the second sequence directly.  Instead only the \"abcd\" can\n",
      "     |      match, and matches the leftmost \"abcd\" in the second sequence:\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\")\n",
      "     |      >>> s.find_longest_match(0, 5, 0, 9)\n",
      "     |      Match(a=1, b=0, size=4)\n",
      "     |      \n",
      "     |      If no blocks match, return (alo, blo, 0).\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(None, \"ab\", \"c\")\n",
      "     |      >>> s.find_longest_match(0, 2, 0, 1)\n",
      "     |      Match(a=0, b=0, size=0)\n",
      "     |  \n",
      "     |  get_grouped_opcodes(self, n=3)\n",
      "     |      Isolate change clusters by eliminating ranges with no changes.\n",
      "     |      \n",
      "     |      Return a generator of groups with up to n lines of context.\n",
      "     |      Each group is in the same format as returned by get_opcodes().\n",
      "     |      \n",
      "     |      >>> from pprint import pprint\n",
      "     |      >>> a = list(map(str, range(1,40)))\n",
      "     |      >>> b = a[:]\n",
      "     |      >>> b[8:8] = ['i']     # Make an insertion\n",
      "     |      >>> b[20] += 'x'       # Make a replacement\n",
      "     |      >>> b[23:28] = []      # Make a deletion\n",
      "     |      >>> b[30] += 'y'       # Make another replacement\n",
      "     |      >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))\n",
      "     |      [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],\n",
      "     |       [('equal', 16, 19, 17, 20),\n",
      "     |        ('replace', 19, 20, 20, 21),\n",
      "     |        ('equal', 20, 22, 21, 23),\n",
      "     |        ('delete', 22, 27, 23, 23),\n",
      "     |        ('equal', 27, 30, 23, 26)],\n",
      "     |       [('equal', 31, 34, 27, 30),\n",
      "     |        ('replace', 34, 35, 30, 31),\n",
      "     |        ('equal', 35, 38, 31, 34)]]\n",
      "     |  \n",
      "     |  get_matching_blocks(self)\n",
      "     |      Return list of triples describing matching subsequences.\n",
      "     |      \n",
      "     |      Each triple is of the form (i, j, n), and means that\n",
      "     |      a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in\n",
      "     |      i and in j.  New in Python 2.5, it's also guaranteed that if\n",
      "     |      (i, j, n) and (i', j', n') are adjacent triples in the list, and\n",
      "     |      the second is not the last triple in the list, then i+n != i' or\n",
      "     |      j+n != j'.  IOW, adjacent triples never describe adjacent equal\n",
      "     |      blocks.\n",
      "     |      \n",
      "     |      The last triple is a dummy, (len(a), len(b), 0), and is the only\n",
      "     |      triple with n==0.\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\")\n",
      "     |      >>> list(s.get_matching_blocks())\n",
      "     |      [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]\n",
      "     |  \n",
      "     |  get_opcodes(self)\n",
      "     |      Return list of 5-tuples describing how to turn a into b.\n",
      "     |      \n",
      "     |      Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple\n",
      "     |      has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the\n",
      "     |      tuple preceding it, and likewise for j1 == the previous j2.\n",
      "     |      \n",
      "     |      The tags are strings, with these meanings:\n",
      "     |      \n",
      "     |      'replace':  a[i1:i2] should be replaced by b[j1:j2]\n",
      "     |      'delete':   a[i1:i2] should be deleted.\n",
      "     |                  Note that j1==j2 in this case.\n",
      "     |      'insert':   b[j1:j2] should be inserted at a[i1:i1].\n",
      "     |                  Note that i1==i2 in this case.\n",
      "     |      'equal':    a[i1:i2] == b[j1:j2]\n",
      "     |      \n",
      "     |      >>> a = \"qabxcd\"\n",
      "     |      >>> b = \"abycdf\"\n",
      "     |      >>> s = SequenceMatcher(None, a, b)\n",
      "     |      >>> for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
      "     |      ...    print((\"%7s a[%d:%d] (%s) b[%d:%d] (%s)\" %\n",
      "     |      ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))\n",
      "     |       delete a[0:1] (q) b[0:0] ()\n",
      "     |        equal a[1:3] (ab) b[0:2] (ab)\n",
      "     |      replace a[3:4] (x) b[2:3] (y)\n",
      "     |        equal a[4:6] (cd) b[3:5] (cd)\n",
      "     |       insert a[6:6] () b[5:6] (f)\n",
      "     |  \n",
      "     |  quick_ratio(self)\n",
      "     |      Return an upper bound on ratio() relatively quickly.\n",
      "     |      \n",
      "     |      This isn't defined beyond that it is an upper bound on .ratio(), and\n",
      "     |      is faster to compute.\n",
      "     |  \n",
      "     |  ratio(self)\n",
      "     |      Return a measure of the sequences' similarity (float in [0,1]).\n",
      "     |      \n",
      "     |      Where T is the total number of elements in both sequences, and\n",
      "     |      M is the number of matches, this is 2.0*M / T.\n",
      "     |      Note that this is 1 if the sequences are identical, and 0 if\n",
      "     |      they have nothing in common.\n",
      "     |      \n",
      "     |      .ratio() is expensive to compute if you haven't already computed\n",
      "     |      .get_matching_blocks() or .get_opcodes(), in which case you may\n",
      "     |      want to try .quick_ratio() or .real_quick_ratio() first to get an\n",
      "     |      upper bound.\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n",
      "     |      >>> s.ratio()\n",
      "     |      0.75\n",
      "     |      >>> s.quick_ratio()\n",
      "     |      0.75\n",
      "     |      >>> s.real_quick_ratio()\n",
      "     |      1.0\n",
      "     |  \n",
      "     |  real_quick_ratio(self)\n",
      "     |      Return an upper bound on ratio() very quickly.\n",
      "     |      \n",
      "     |      This isn't defined beyond that it is an upper bound on .ratio(), and\n",
      "     |      is faster to compute than either .ratio() or .quick_ratio().\n",
      "     |  \n",
      "     |  set_seq1(self, a)\n",
      "     |      Set the first sequence to be compared.\n",
      "     |      \n",
      "     |      The second sequence to be compared is not changed.\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n",
      "     |      >>> s.ratio()\n",
      "     |      0.75\n",
      "     |      >>> s.set_seq1(\"bcde\")\n",
      "     |      >>> s.ratio()\n",
      "     |      1.0\n",
      "     |      >>>\n",
      "     |      \n",
      "     |      SequenceMatcher computes and caches detailed information about the\n",
      "     |      second sequence, so if you want to compare one sequence S against\n",
      "     |      many sequences, use .set_seq2(S) once and call .set_seq1(x)\n",
      "     |      repeatedly for each of the other sequences.\n",
      "     |      \n",
      "     |      See also set_seqs() and set_seq2().\n",
      "     |  \n",
      "     |  set_seq2(self, b)\n",
      "     |      Set the second sequence to be compared.\n",
      "     |      \n",
      "     |      The first sequence to be compared is not changed.\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n",
      "     |      >>> s.ratio()\n",
      "     |      0.75\n",
      "     |      >>> s.set_seq2(\"abcd\")\n",
      "     |      >>> s.ratio()\n",
      "     |      1.0\n",
      "     |      >>>\n",
      "     |      \n",
      "     |      SequenceMatcher computes and caches detailed information about the\n",
      "     |      second sequence, so if you want to compare one sequence S against\n",
      "     |      many sequences, use .set_seq2(S) once and call .set_seq1(x)\n",
      "     |      repeatedly for each of the other sequences.\n",
      "     |      \n",
      "     |      See also set_seqs() and set_seq1().\n",
      "     |  \n",
      "     |  set_seqs(self, a, b)\n",
      "     |      Set the two sequences to be compared.\n",
      "     |      \n",
      "     |      >>> s = SequenceMatcher()\n",
      "     |      >>> s.set_seqs(\"abcd\", \"bcde\")\n",
      "     |      >>> s.ratio()\n",
      "     |      0.75\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    IS_CHARACTER_JUNK(ch, ws=' \\t')\n",
      "        Return True for ignorable character: iff `ch` is a space or tab.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> IS_CHARACTER_JUNK(' ')\n",
      "        True\n",
      "        >>> IS_CHARACTER_JUNK('\\t')\n",
      "        True\n",
      "        >>> IS_CHARACTER_JUNK('\\n')\n",
      "        False\n",
      "        >>> IS_CHARACTER_JUNK('x')\n",
      "        False\n",
      "    \n",
      "    IS_LINE_JUNK(line, pat=<built-in method match of re.Pattern object at 0x000002595F2C93F0>)\n",
      "        Return True for ignorable line: iff `line` is blank or contains a single '#'.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> IS_LINE_JUNK('\\n')\n",
      "        True\n",
      "        >>> IS_LINE_JUNK('  #   \\n')\n",
      "        True\n",
      "        >>> IS_LINE_JUNK('hello\\n')\n",
      "        False\n",
      "    \n",
      "    context_diff(a, b, fromfile='', tofile='', fromfiledate='', tofiledate='', n=3, lineterm='\\n')\n",
      "        Compare two sequences of lines; generate the delta as a context diff.\n",
      "        \n",
      "        Context diffs are a compact way of showing line changes and a few\n",
      "        lines of context.  The number of context lines is set by 'n' which\n",
      "        defaults to three.\n",
      "        \n",
      "        By default, the diff control lines (those with *** or ---) are\n",
      "        created with a trailing newline.  This is helpful so that inputs\n",
      "        created from file.readlines() result in diffs that are suitable for\n",
      "        file.writelines() since both the inputs and outputs have trailing\n",
      "        newlines.\n",
      "        \n",
      "        For inputs that do not have trailing newlines, set the lineterm\n",
      "        argument to \"\" so that the output will be uniformly newline free.\n",
      "        \n",
      "        The context diff format normally has a header for filenames and\n",
      "        modification times.  Any or all of these may be specified using\n",
      "        strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.\n",
      "        The modification times are normally expressed in the ISO 8601 format.\n",
      "        If not specified, the strings default to blanks.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> print(''.join(context_diff('one\\ntwo\\nthree\\nfour\\n'.splitlines(True),\n",
      "        ...       'zero\\none\\ntree\\nfour\\n'.splitlines(True), 'Original', 'Current')),\n",
      "        ...       end=\"\")\n",
      "        *** Original\n",
      "        --- Current\n",
      "        ***************\n",
      "        *** 1,4 ****\n",
      "          one\n",
      "        ! two\n",
      "        ! three\n",
      "          four\n",
      "        --- 1,4 ----\n",
      "        + zero\n",
      "          one\n",
      "        ! tree\n",
      "          four\n",
      "    \n",
      "    diff_bytes(dfunc, a, b, fromfile=b'', tofile=b'', fromfiledate=b'', tofiledate=b'', n=3, lineterm=b'\\n')\n",
      "        Compare `a` and `b`, two sequences of lines represented as bytes rather\n",
      "        than str. This is a wrapper for `dfunc`, which is typically either\n",
      "        unified_diff() or context_diff(). Inputs are losslessly converted to\n",
      "        strings so that `dfunc` only has to worry about strings, and encoded\n",
      "        back to bytes on return. This is necessary to compare files with\n",
      "        unknown or inconsistent encoding. All other inputs (except `n`) must be\n",
      "        bytes rather than str.\n",
      "    \n",
      "    get_close_matches(word, possibilities, n=3, cutoff=0.6)\n",
      "        Use SequenceMatcher to return list of the best \"good enough\" matches.\n",
      "        \n",
      "        word is a sequence for which close matches are desired (typically a\n",
      "        string).\n",
      "        \n",
      "        possibilities is a list of sequences against which to match word\n",
      "        (typically a list of strings).\n",
      "        \n",
      "        Optional arg n (default 3) is the maximum number of close matches to\n",
      "        return.  n must be > 0.\n",
      "        \n",
      "        Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities\n",
      "        that don't score at least that similar to word are ignored.\n",
      "        \n",
      "        The best (no more than n) matches among the possibilities are returned\n",
      "        in a list, sorted by similarity score, most similar first.\n",
      "        \n",
      "        >>> get_close_matches(\"appel\", [\"ape\", \"apple\", \"peach\", \"puppy\"])\n",
      "        ['apple', 'ape']\n",
      "        >>> import keyword as _keyword\n",
      "        >>> get_close_matches(\"wheel\", _keyword.kwlist)\n",
      "        ['while']\n",
      "        >>> get_close_matches(\"Apple\", _keyword.kwlist)\n",
      "        []\n",
      "        >>> get_close_matches(\"accept\", _keyword.kwlist)\n",
      "        ['except']\n",
      "    \n",
      "    ndiff(a, b, linejunk=None, charjunk=<function IS_CHARACTER_JUNK at 0x000002595F2DCF70>)\n",
      "        Compare `a` and `b` (lists of strings); return a `Differ`-style delta.\n",
      "        \n",
      "        Optional keyword parameters `linejunk` and `charjunk` are for filter\n",
      "        functions, or can be None:\n",
      "        \n",
      "        - linejunk: A function that should accept a single string argument and\n",
      "          return true iff the string is junk.  The default is None, and is\n",
      "          recommended; the underlying SequenceMatcher class has an adaptive\n",
      "          notion of \"noise\" lines.\n",
      "        \n",
      "        - charjunk: A function that accepts a character (string of length\n",
      "          1), and returns true iff the character is junk. The default is\n",
      "          the module-level function IS_CHARACTER_JUNK, which filters out\n",
      "          whitespace characters (a blank or tab; note: it's a bad idea to\n",
      "          include newline in this!).\n",
      "        \n",
      "        Tools/scripts/ndiff.py is a command-line front-end to this function.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> diff = ndiff('one\\ntwo\\nthree\\n'.splitlines(keepends=True),\n",
      "        ...              'ore\\ntree\\nemu\\n'.splitlines(keepends=True))\n",
      "        >>> print(''.join(diff), end=\"\")\n",
      "        - one\n",
      "        ?  ^\n",
      "        + ore\n",
      "        ?  ^\n",
      "        - two\n",
      "        - three\n",
      "        ?  -\n",
      "        + tree\n",
      "        + emu\n",
      "    \n",
      "    restore(delta, which)\n",
      "        Generate one of the two sequences that generated a delta.\n",
      "        \n",
      "        Given a `delta` produced by `Differ.compare()` or `ndiff()`, extract\n",
      "        lines originating from file 1 or 2 (parameter `which`), stripping off line\n",
      "        prefixes.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> diff = ndiff('one\\ntwo\\nthree\\n'.splitlines(keepends=True),\n",
      "        ...              'ore\\ntree\\nemu\\n'.splitlines(keepends=True))\n",
      "        >>> diff = list(diff)\n",
      "        >>> print(''.join(restore(diff, 1)), end=\"\")\n",
      "        one\n",
      "        two\n",
      "        three\n",
      "        >>> print(''.join(restore(diff, 2)), end=\"\")\n",
      "        ore\n",
      "        tree\n",
      "        emu\n",
      "    \n",
      "    unified_diff(a, b, fromfile='', tofile='', fromfiledate='', tofiledate='', n=3, lineterm='\\n')\n",
      "        Compare two sequences of lines; generate the delta as a unified diff.\n",
      "        \n",
      "        Unified diffs are a compact way of showing line changes and a few\n",
      "        lines of context.  The number of context lines is set by 'n' which\n",
      "        defaults to three.\n",
      "        \n",
      "        By default, the diff control lines (those with ---, +++, or @@) are\n",
      "        created with a trailing newline.  This is helpful so that inputs\n",
      "        created from file.readlines() result in diffs that are suitable for\n",
      "        file.writelines() since both the inputs and outputs have trailing\n",
      "        newlines.\n",
      "        \n",
      "        For inputs that do not have trailing newlines, set the lineterm\n",
      "        argument to \"\" so that the output will be uniformly newline free.\n",
      "        \n",
      "        The unidiff format normally has a header for filenames and modification\n",
      "        times.  Any or all of these may be specified using strings for\n",
      "        'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.\n",
      "        The modification times are normally expressed in the ISO 8601 format.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> for line in unified_diff('one two three four'.split(),\n",
      "        ...             'zero one tree four'.split(), 'Original', 'Current',\n",
      "        ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',\n",
      "        ...             lineterm=''):\n",
      "        ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE\n",
      "        --- Original        2005-01-26 23:30:50\n",
      "        +++ Current         2010-04-02 10:20:52\n",
      "        @@ -1,4 +1,4 @@\n",
      "        +zero\n",
      "         one\n",
      "        -two\n",
      "        -three\n",
      "        +tree\n",
      "         four\n",
      "\n",
      "DATA\n",
      "    __all__ = ['get_close_matches', 'ndiff', 'restore', 'SequenceMatcher',...\n",
      "\n",
      "FILE\n",
      "    d:\\python\\wpy64-3820\\python-3.8.2.amd64\\lib\\difflib.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "help(difflib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differ',\n",
       " 'HtmlDiff',\n",
       " 'IS_CHARACTER_JUNK',\n",
       " 'IS_LINE_JUNK',\n",
       " 'Match',\n",
       " 'SequenceMatcher',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_calculate_ratio',\n",
       " '_check_types',\n",
       " '_file_template',\n",
       " '_format_range_context',\n",
       " '_format_range_unified',\n",
       " '_keep_original_ws',\n",
       " '_legend',\n",
       " '_mdiff',\n",
       " '_namedtuple',\n",
       " '_nlargest',\n",
       " '_styles',\n",
       " '_table_template',\n",
       " '_test',\n",
       " 'context_diff',\n",
       " 'diff_bytes',\n",
       " 'get_close_matches',\n",
       " 'ndiff',\n",
       " 'restore',\n",
       " 'unified_diff']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(difflib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SequenceMatcher in module difflib:\n",
      "\n",
      "class SequenceMatcher(builtins.object)\n",
      " |  SequenceMatcher(isjunk=None, a='', b='', autojunk=True)\n",
      " |  \n",
      " |  SequenceMatcher is a flexible class for comparing pairs of sequences of\n",
      " |  any type, so long as the sequence elements are hashable.  The basic\n",
      " |  algorithm predates, and is a little fancier than, an algorithm\n",
      " |  published in the late 1980's by Ratcliff and Obershelp under the\n",
      " |  hyperbolic name \"gestalt pattern matching\".  The basic idea is to find\n",
      " |  the longest contiguous matching subsequence that contains no \"junk\"\n",
      " |  elements (R-O doesn't address junk).  The same idea is then applied\n",
      " |  recursively to the pieces of the sequences to the left and to the right\n",
      " |  of the matching subsequence.  This does not yield minimal edit\n",
      " |  sequences, but does tend to yield matches that \"look right\" to people.\n",
      " |  \n",
      " |  SequenceMatcher tries to compute a \"human-friendly diff\" between two\n",
      " |  sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the\n",
      " |  longest *contiguous* & junk-free matching subsequence.  That's what\n",
      " |  catches peoples' eyes.  The Windows(tm) windiff has another interesting\n",
      " |  notion, pairing up elements that appear uniquely in each sequence.\n",
      " |  That, and the method here, appear to yield more intuitive difference\n",
      " |  reports than does diff.  This method appears to be the least vulnerable\n",
      " |  to synching up on blocks of \"junk lines\", though (like blank lines in\n",
      " |  ordinary text files, or maybe \"<P>\" lines in HTML files).  That may be\n",
      " |  because this is the only method of the 3 that has a *concept* of\n",
      " |  \"junk\" <wink>.\n",
      " |  \n",
      " |  Example, comparing two strings, and considering blanks to be \"junk\":\n",
      " |  \n",
      " |  >>> s = SequenceMatcher(lambda x: x == \" \",\n",
      " |  ...                     \"private Thread currentThread;\",\n",
      " |  ...                     \"private volatile Thread currentThread;\")\n",
      " |  >>>\n",
      " |  \n",
      " |  .ratio() returns a float in [0, 1], measuring the \"similarity\" of the\n",
      " |  sequences.  As a rule of thumb, a .ratio() value over 0.6 means the\n",
      " |  sequences are close matches:\n",
      " |  \n",
      " |  >>> print(round(s.ratio(), 3))\n",
      " |  0.866\n",
      " |  >>>\n",
      " |  \n",
      " |  If you're only interested in where the sequences match,\n",
      " |  .get_matching_blocks() is handy:\n",
      " |  \n",
      " |  >>> for block in s.get_matching_blocks():\n",
      " |  ...     print(\"a[%d] and b[%d] match for %d elements\" % block)\n",
      " |  a[0] and b[0] match for 8 elements\n",
      " |  a[8] and b[17] match for 21 elements\n",
      " |  a[29] and b[38] match for 0 elements\n",
      " |  \n",
      " |  Note that the last tuple returned by .get_matching_blocks() is always a\n",
      " |  dummy, (len(a), len(b), 0), and this is the only case in which the last\n",
      " |  tuple element (number of elements matched) is 0.\n",
      " |  \n",
      " |  If you want to know how to change the first sequence into the second,\n",
      " |  use .get_opcodes():\n",
      " |  \n",
      " |  >>> for opcode in s.get_opcodes():\n",
      " |  ...     print(\"%6s a[%d:%d] b[%d:%d]\" % opcode)\n",
      " |   equal a[0:8] b[0:8]\n",
      " |  insert a[8:8] b[8:17]\n",
      " |   equal a[8:29] b[17:38]\n",
      " |  \n",
      " |  See the Differ class for a fancy human-friendly file differencer, which\n",
      " |  uses SequenceMatcher both to compare sequences of lines, and to compare\n",
      " |  sequences of characters within similar (near-matching) lines.\n",
      " |  \n",
      " |  See also function get_close_matches() in this module, which shows how\n",
      " |  simple code building on SequenceMatcher can be used to do useful work.\n",
      " |  \n",
      " |  Timing:  Basic R-O is cubic time worst case and quadratic time expected\n",
      " |  case.  SequenceMatcher is quadratic time for the worst case and has\n",
      " |  expected-case behavior dependent in a complicated way on how many\n",
      " |  elements the sequences have in common; best case time is linear.\n",
      " |  \n",
      " |  Methods:\n",
      " |  \n",
      " |  __init__(isjunk=None, a='', b='')\n",
      " |      Construct a SequenceMatcher.\n",
      " |  \n",
      " |  set_seqs(a, b)\n",
      " |      Set the two sequences to be compared.\n",
      " |  \n",
      " |  set_seq1(a)\n",
      " |      Set the first sequence to be compared.\n",
      " |  \n",
      " |  set_seq2(b)\n",
      " |      Set the second sequence to be compared.\n",
      " |  \n",
      " |  find_longest_match(alo, ahi, blo, bhi)\n",
      " |      Find longest matching block in a[alo:ahi] and b[blo:bhi].\n",
      " |  \n",
      " |  get_matching_blocks()\n",
      " |      Return list of triples describing matching subsequences.\n",
      " |  \n",
      " |  get_opcodes()\n",
      " |      Return list of 5-tuples describing how to turn a into b.\n",
      " |  \n",
      " |  ratio()\n",
      " |      Return a measure of the sequences' similarity (float in [0,1]).\n",
      " |  \n",
      " |  quick_ratio()\n",
      " |      Return an upper bound on .ratio() relatively quickly.\n",
      " |  \n",
      " |  real_quick_ratio()\n",
      " |      Return an upper bound on ratio() very quickly.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, isjunk=None, a='', b='', autojunk=True)\n",
      " |      Construct a SequenceMatcher.\n",
      " |      \n",
      " |      Optional arg isjunk is None (the default), or a one-argument\n",
      " |      function that takes a sequence element and returns true iff the\n",
      " |      element is junk.  None is equivalent to passing \"lambda x: 0\", i.e.\n",
      " |      no elements are considered to be junk.  For example, pass\n",
      " |          lambda x: x in \" \\t\"\n",
      " |      if you're comparing lines as sequences of characters, and don't\n",
      " |      want to synch up on blanks or hard tabs.\n",
      " |      \n",
      " |      Optional arg a is the first of two sequences to be compared.  By\n",
      " |      default, an empty string.  The elements of a must be hashable.  See\n",
      " |      also .set_seqs() and .set_seq1().\n",
      " |      \n",
      " |      Optional arg b is the second of two sequences to be compared.  By\n",
      " |      default, an empty string.  The elements of b must be hashable. See\n",
      " |      also .set_seqs() and .set_seq2().\n",
      " |      \n",
      " |      Optional arg autojunk should be set to False to disable the\n",
      " |      \"automatic junk heuristic\" that treats popular elements as junk\n",
      " |      (see module documentation for more information).\n",
      " |  \n",
      " |  find_longest_match(self, alo, ahi, blo, bhi)\n",
      " |      Find longest matching block in a[alo:ahi] and b[blo:bhi].\n",
      " |      \n",
      " |      If isjunk is not defined:\n",
      " |      \n",
      " |      Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where\n",
      " |          alo <= i <= i+k <= ahi\n",
      " |          blo <= j <= j+k <= bhi\n",
      " |      and for all (i',j',k') meeting those conditions,\n",
      " |          k >= k'\n",
      " |          i <= i'\n",
      " |          and if i == i', j <= j'\n",
      " |      \n",
      " |      In other words, of all maximal matching blocks, return one that\n",
      " |      starts earliest in a, and of all those maximal matching blocks that\n",
      " |      start earliest in a, return the one that starts earliest in b.\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(None, \" abcd\", \"abcd abcd\")\n",
      " |      >>> s.find_longest_match(0, 5, 0, 9)\n",
      " |      Match(a=0, b=4, size=5)\n",
      " |      \n",
      " |      If isjunk is defined, first the longest matching block is\n",
      " |      determined as above, but with the additional restriction that no\n",
      " |      junk element appears in the block.  Then that block is extended as\n",
      " |      far as possible by matching (only) junk elements on both sides.  So\n",
      " |      the resulting block never matches on junk except as identical junk\n",
      " |      happens to be adjacent to an \"interesting\" match.\n",
      " |      \n",
      " |      Here's the same example as before, but considering blanks to be\n",
      " |      junk.  That prevents \" abcd\" from matching the \" abcd\" at the tail\n",
      " |      end of the second sequence directly.  Instead only the \"abcd\" can\n",
      " |      match, and matches the leftmost \"abcd\" in the second sequence:\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\")\n",
      " |      >>> s.find_longest_match(0, 5, 0, 9)\n",
      " |      Match(a=1, b=0, size=4)\n",
      " |      \n",
      " |      If no blocks match, return (alo, blo, 0).\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(None, \"ab\", \"c\")\n",
      " |      >>> s.find_longest_match(0, 2, 0, 1)\n",
      " |      Match(a=0, b=0, size=0)\n",
      " |  \n",
      " |  get_grouped_opcodes(self, n=3)\n",
      " |      Isolate change clusters by eliminating ranges with no changes.\n",
      " |      \n",
      " |      Return a generator of groups with up to n lines of context.\n",
      " |      Each group is in the same format as returned by get_opcodes().\n",
      " |      \n",
      " |      >>> from pprint import pprint\n",
      " |      >>> a = list(map(str, range(1,40)))\n",
      " |      >>> b = a[:]\n",
      " |      >>> b[8:8] = ['i']     # Make an insertion\n",
      " |      >>> b[20] += 'x'       # Make a replacement\n",
      " |      >>> b[23:28] = []      # Make a deletion\n",
      " |      >>> b[30] += 'y'       # Make another replacement\n",
      " |      >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))\n",
      " |      [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],\n",
      " |       [('equal', 16, 19, 17, 20),\n",
      " |        ('replace', 19, 20, 20, 21),\n",
      " |        ('equal', 20, 22, 21, 23),\n",
      " |        ('delete', 22, 27, 23, 23),\n",
      " |        ('equal', 27, 30, 23, 26)],\n",
      " |       [('equal', 31, 34, 27, 30),\n",
      " |        ('replace', 34, 35, 30, 31),\n",
      " |        ('equal', 35, 38, 31, 34)]]\n",
      " |  \n",
      " |  get_matching_blocks(self)\n",
      " |      Return list of triples describing matching subsequences.\n",
      " |      \n",
      " |      Each triple is of the form (i, j, n), and means that\n",
      " |      a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in\n",
      " |      i and in j.  New in Python 2.5, it's also guaranteed that if\n",
      " |      (i, j, n) and (i', j', n') are adjacent triples in the list, and\n",
      " |      the second is not the last triple in the list, then i+n != i' or\n",
      " |      j+n != j'.  IOW, adjacent triples never describe adjacent equal\n",
      " |      blocks.\n",
      " |      \n",
      " |      The last triple is a dummy, (len(a), len(b), 0), and is the only\n",
      " |      triple with n==0.\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\")\n",
      " |      >>> list(s.get_matching_blocks())\n",
      " |      [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]\n",
      " |  \n",
      " |  get_opcodes(self)\n",
      " |      Return list of 5-tuples describing how to turn a into b.\n",
      " |      \n",
      " |      Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple\n",
      " |      has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the\n",
      " |      tuple preceding it, and likewise for j1 == the previous j2.\n",
      " |      \n",
      " |      The tags are strings, with these meanings:\n",
      " |      \n",
      " |      'replace':  a[i1:i2] should be replaced by b[j1:j2]\n",
      " |      'delete':   a[i1:i2] should be deleted.\n",
      " |                  Note that j1==j2 in this case.\n",
      " |      'insert':   b[j1:j2] should be inserted at a[i1:i1].\n",
      " |                  Note that i1==i2 in this case.\n",
      " |      'equal':    a[i1:i2] == b[j1:j2]\n",
      " |      \n",
      " |      >>> a = \"qabxcd\"\n",
      " |      >>> b = \"abycdf\"\n",
      " |      >>> s = SequenceMatcher(None, a, b)\n",
      " |      >>> for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
      " |      ...    print((\"%7s a[%d:%d] (%s) b[%d:%d] (%s)\" %\n",
      " |      ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))\n",
      " |       delete a[0:1] (q) b[0:0] ()\n",
      " |        equal a[1:3] (ab) b[0:2] (ab)\n",
      " |      replace a[3:4] (x) b[2:3] (y)\n",
      " |        equal a[4:6] (cd) b[3:5] (cd)\n",
      " |       insert a[6:6] () b[5:6] (f)\n",
      " |  \n",
      " |  quick_ratio(self)\n",
      " |      Return an upper bound on ratio() relatively quickly.\n",
      " |      \n",
      " |      This isn't defined beyond that it is an upper bound on .ratio(), and\n",
      " |      is faster to compute.\n",
      " |  \n",
      " |  ratio(self)\n",
      " |      Return a measure of the sequences' similarity (float in [0,1]).\n",
      " |      \n",
      " |      Where T is the total number of elements in both sequences, and\n",
      " |      M is the number of matches, this is 2.0*M / T.\n",
      " |      Note that this is 1 if the sequences are identical, and 0 if\n",
      " |      they have nothing in common.\n",
      " |      \n",
      " |      .ratio() is expensive to compute if you haven't already computed\n",
      " |      .get_matching_blocks() or .get_opcodes(), in which case you may\n",
      " |      want to try .quick_ratio() or .real_quick_ratio() first to get an\n",
      " |      upper bound.\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n",
      " |      >>> s.ratio()\n",
      " |      0.75\n",
      " |      >>> s.quick_ratio()\n",
      " |      0.75\n",
      " |      >>> s.real_quick_ratio()\n",
      " |      1.0\n",
      " |  \n",
      " |  real_quick_ratio(self)\n",
      " |      Return an upper bound on ratio() very quickly.\n",
      " |      \n",
      " |      This isn't defined beyond that it is an upper bound on .ratio(), and\n",
      " |      is faster to compute than either .ratio() or .quick_ratio().\n",
      " |  \n",
      " |  set_seq1(self, a)\n",
      " |      Set the first sequence to be compared.\n",
      " |      \n",
      " |      The second sequence to be compared is not changed.\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n",
      " |      >>> s.ratio()\n",
      " |      0.75\n",
      " |      >>> s.set_seq1(\"bcde\")\n",
      " |      >>> s.ratio()\n",
      " |      1.0\n",
      " |      >>>\n",
      " |      \n",
      " |      SequenceMatcher computes and caches detailed information about the\n",
      " |      second sequence, so if you want to compare one sequence S against\n",
      " |      many sequences, use .set_seq2(S) once and call .set_seq1(x)\n",
      " |      repeatedly for each of the other sequences.\n",
      " |      \n",
      " |      See also set_seqs() and set_seq2().\n",
      " |  \n",
      " |  set_seq2(self, b)\n",
      " |      Set the second sequence to be compared.\n",
      " |      \n",
      " |      The first sequence to be compared is not changed.\n",
      " |      \n",
      " |      >>> s = SequenceMatcher(None, \"abcd\", \"bcde\")\n",
      " |      >>> s.ratio()\n",
      " |      0.75\n",
      " |      >>> s.set_seq2(\"abcd\")\n",
      " |      >>> s.ratio()\n",
      " |      1.0\n",
      " |      >>>\n",
      " |      \n",
      " |      SequenceMatcher computes and caches detailed information about the\n",
      " |      second sequence, so if you want to compare one sequence S against\n",
      " |      many sequences, use .set_seq2(S) once and call .set_seq1(x)\n",
      " |      repeatedly for each of the other sequences.\n",
      " |      \n",
      " |      See also set_seqs() and set_seq1().\n",
      " |  \n",
      " |  set_seqs(self, a, b)\n",
      " |      Set the two sequences to be compared.\n",
      " |      \n",
      " |      >>> s = SequenceMatcher()\n",
      " |      >>> s.set_seqs(\"abcd\", \"bcde\")\n",
      " |      >>> s.ratio()\n",
      " |      0.75\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "help(SequenceMatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<difflib.SequenceMatcher at 0x259612c49a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(None, \"book\",\"booked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(None, \"book\",\"booked\").ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(None, \"book\",\"boo\").ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(None, \"book\",\"prebook\").ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(None, \"book\",\"postboks\").ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boo', 'booked', 'prebook', 'postboks']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflib.get_close_matches(\"book\",[\"booked\",\"prebook\",\"boo\",\"postboks\"],n=4, cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_close_matches in module difflib:\n",
      "\n",
      "get_close_matches(word, possibilities, n=3, cutoff=0.6)\n",
      "    Use SequenceMatcher to return list of the best \"good enough\" matches.\n",
      "    \n",
      "    word is a sequence for which close matches are desired (typically a\n",
      "    string).\n",
      "    \n",
      "    possibilities is a list of sequences against which to match word\n",
      "    (typically a list of strings).\n",
      "    \n",
      "    Optional arg n (default 3) is the maximum number of close matches to\n",
      "    return.  n must be > 0.\n",
      "    \n",
      "    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities\n",
      "    that don't score at least that similar to word are ignored.\n",
      "    \n",
      "    The best (no more than n) matches among the possibilities are returned\n",
      "    in a list, sorted by similarity score, most similar first.\n",
      "    \n",
      "    >>> get_close_matches(\"appel\", [\"ape\", \"apple\", \"peach\", \"puppy\"])\n",
      "    ['apple', 'ape']\n",
      "    >>> import keyword as _keyword\n",
      "    >>> get_close_matches(\"wheel\", _keyword.kwlist)\n",
      "    ['while']\n",
      "    >>> get_close_matches(\"Apple\", _keyword.kwlist)\n",
      "    []\n",
      "    >>> get_close_matches(\"accept\", _keyword.kwlist)\n",
      "    ['except']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(difflib.get_close_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'ape']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflib.get_close_matches(\"appel\", [\"ape\", \"apple\", \"peach\", \"puppy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflib.get_close_matches(\"appel\", [\"ape\", \"apple\", \"peach\", \"puppy\"], n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'ape', 'puppy', 'peach']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflib.get_close_matches(\"appel\", [\"ape\", \"apple\", \"peach\", \"puppy\"], n=5,cutoff = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example:\n",
    "import json\n",
    "\n",
    "# json file downloaded from https://raw.githubusercontent.com/matthewreagan/WebstersEnglishDictionary/master/dictionary.json\n",
    "# load the json data into python object\n",
    "json_dictionary = dict()\n",
    "with open(\"dictionary.json\") as dictionary_file:\n",
    "    json_dictionary = json.load(dictionary_file)\n",
    "    \n",
    "# get input from the user    \n",
    "in_word = input(\"Search meaning of word : \")\n",
    "if (in_word in json_dictionary.keys()):\n",
    "    print(json_dictionary[in_word.lower()])\n",
    "else:\n",
    "    \n",
    "\n",
    "#difflib-> get_close_matches\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
